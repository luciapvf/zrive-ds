{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, roc_auc_score, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple\n",
    "from plotnine import ggplot, aes, geom_point, geom_smooth, labs, theme_bw\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "id": "15123af711e6258e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "CONTEXTO:\n",
    "Enviar notificaciones push a clientes para animarlos a comprar un producto que ya han seleccionado previamente.\n",
    "\n",
    "OBJETIVO:\n",
    "Desarrollar un modelo de aprendizaje automático que dado un usuarioo y un producto prediga si el usuario\n",
    "compraría el produco si estuviera comprando con nosotros en ese momento.\n",
    "\n",
    "DATOS:\n",
    "Usar la base de datos feature_frame.csv filtrando sólo los pedidos de al menos 5 productos. En este caso,\n",
    "uso directamente feature_frame_filtered.csv que filtra dichos pedidos.\n",
    "\"\"\""
   ],
   "id": "cb8b3f619a551fcc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# CONSTRUCCIÓN DEL MODELO LINEAL PREDICTIVO",
   "id": "d5d6cedc96d64c99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#1. Se cargan los datos\n",
    "BASE_DIR = os.getcwd()  # obtiene el directorio actual\n",
    "DATA_PATH = os.path.join(BASE_DIR, \"data\", \"feature_frame_filtered.csv\")\n",
    "\n",
    "print(\"Cargando datos desde:\", DATA_PATH)\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Datos cargados correctamente:\", df.shape)"
   ],
   "id": "b3d2c2ddce7644a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.head # para ver las primeras filas",
   "id": "380d8acebac9307a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.info() # para ver tipo de datos, si hay nulos",
   "id": "38ced770befe636"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Clasificación de columnas\n",
    "info_col = [\"variant_id\", \"order_id\", \"user_id\", \"created_at\",\n",
    "            \"order_date\"]  # id y fechas (son distintos de cada pedido)\n",
    "label_col = \"outcome\"  # variable objetivo (y)\n",
    "features_col = [col for col in df.columns if col not in info_col + [label_col]]  # resto de columnas\n",
    "\n",
    "categorical_col = [\"predict_type\", \"vendor\"]  # columnas categóricas (de las features)\n",
    "binary_col = [\"ordered_before\", \"abandoned_before\", \"active_snoozed\",\n",
    "              \"set_as_regular\"]  # columnas binarias (de las features)\n",
    "numerical_col = [col for col in features_col if col not in categorical_col + binary_col]  # resto (de las features)"
   ],
   "id": "9c8d1d5527ccb53b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 2. Proceso de entrenamiento, validación y test\n",
    "# NOTA: Se tiene que hacer un SPLIT TEMPORAL, para evitar INFORMATION LEAKAGE. Es decir, respeto el orden temportal de los datos. Quiero que el proceso de entretanmiento, validación sean lo más cercano posible al proceso de producción."
   ],
   "id": "659a471bebf4d95a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# En la gráfica de los perdidos por días, los dividimos en 3 columnas y cada parte se encarga de hacer train, val y test.\n",
    "daily_orders = df.groupby(\"order_date\").order_id.nunique()  # pedidos diarios\n",
    "daily_orders.head()  # primeras filas\n",
    "\n",
    "df[\"order_date\"] = pd.to_datetime(df[\"order_date\"])  # eje x, convertir a datetime si no lo es\n",
    "daily_orders = df.groupby(\"order_date\").order_id.nunique()  # agrupo por fecha\n",
    "\n",
    "plt.plot(daily_orders, label=\"daily_orders\")  # presentación\n",
    "plt.title(\"Pedidos Diarios\")\n",
    "# De este modo, una orden (pedido) o está en train, o en validación o en test.\n",
    "# Entreno con el 70% de los datos y valido con el 90%."
   ],
   "id": "c50a077f43062982"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Para ello, creo una función que me defina el nº de pedidos acumulativos.\n",
    "orders_acum = daily_orders.cumsum() / daily_orders.sum()\n",
    "\n",
    "plt.plot(orders_acum, label=\"orders_acum\")  # represento (tiene que dar 1 la suma obv)\n",
    "plt.title(\"Suma acumulativa de pedidos\")\n",
    "# Realizo la división (cut off).\n",
    "train_val_cutoff = orders_acum[orders_acum <= 0.7].idxmax()\n",
    "val_test_cutoff = orders_acum[orders_acum <= 0.9].idxmax()\n",
    "\n",
    "print(\"Entrenamiendo desde:\", orders_acum.index.min())\n",
    "print(\"Entranmiento hasta:\", train_val_cutoff)\n",
    "print(\"Validación hasta:\", val_test_cutoff)\n",
    "print(\"Test hasta:\", orders_acum.index.max())"
   ],
   "id": "4617859dbbddc75c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Comprobaciones\n",
    "train_df = df[df.order_date <= train_val_cutoff]\n",
    "val_df = df[(df.order_date > train_val_cutoff) & (df.order_date <= val_test_cutoff)]\n",
    "test_df = df[df.order_date > val_test_cutoff]"
   ],
   "id": "eb9a8cb416d8e554"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# BASELINE: Siempre hay que hacer una baseline, es decir, un modelo sencillo que nos de métricas que queremos mejorar para producción.\n",
    "# En este caso, como baseline uso la variable product_popularity, ¿cómo de popular es un producto?. La probabilidad de vender un producto depende de su popularidad.\n",
    "# El modelo (baseline) predice la prob. de que un usuario compre un producto si recibe una notificación push. Sin embargo:\n",
    "# Si envío una notificación y el usuario no compra, le molesta → coste negativo (falso positivo).\n",
    "# Si no envío y el usuario habría comprado, pierdo una venta → coste de oportunidad (falso negativo).\n",
    "# Por tanto, no debo enviar notificaciones a todos los usuarios con prob > 0.5, sino solo cuando la ganancia esperada sea positiva."
   ],
   "id": "5af564f33ef5dec4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_metrics(model_name, y_pred, y_test):\n",
    "    \"\"\"\n",
    "    Dibuja curvas Precision–Recall y ROC para un modelo binario.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    model_name : str\n",
    "        Nombre del modelo para la leyenda.\n",
    "    y_pred : array-like\n",
    "        Probabilidades predichas (no etiquetas).\n",
    "    y_test : array-like\n",
    "        Etiquetas reales (0/1).\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    fig, ax : matplotlib.figure.Figure, matplotlib.axes._subplots.AxesSubplot\n",
    "        Figura y ejes de los subplots.\n",
    "    \"\"\"\n",
    "\n",
    "    # ==========================\n",
    "    # Curva Precision–Recall\n",
    "    # ==========================\n",
    "    recall_, precision_, _ = precision_recall_curve(y_test, y_pred)\n",
    "    avg_precision = average_precision_score(y_test, y_pred)  # PR-AUC estable\n",
    "\n",
    "    # ==========================\n",
    "    # Curva ROC\n",
    "    # ==========================\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    # ==========================\n",
    "    # Crear figura con dos subplots\n",
    "    # ==========================\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # --- Precision–Recall ---\n",
    "    ax[0].plot(recall_, precision_, color='royalblue',\n",
    "               label=f\"{model_name}\\nAP={avg_precision:.3f}\")\n",
    "    ax[0].set_xlabel(\"Recall\")\n",
    "    ax[0].set_ylabel(\"Precision\")\n",
    "    ax[0].set_title(\"Curva Precision–Recall\")\n",
    "    ax[0].set_xlim(0, max(recall_) * 1.05)  # zoom dinámico\n",
    "    ax[0].set_ylim(0, max(precision_) * 1.05)\n",
    "    ax[0].legend(loc=\"upper right\", fontsize=9)\n",
    "    ax[0].grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "    # --- ROC ---\n",
    "    ax[1].plot(fpr, tpr, color='darkorange',\n",
    "               label=f\"{model_name}\\nAUC={roc_auc:.3f}\")\n",
    "    ax[1].plot([0, 1], [0, 1], '--', color='gray', alpha=0.6)\n",
    "    ax[1].set_xlabel(\"False Positive Rate\")\n",
    "    ax[1].set_ylabel(\"True Positive Rate\")\n",
    "    ax[1].set_title(\"Curva ROC\")\n",
    "    ax[1].legend(loc=\"lower right\", fontsize=9)\n",
    "    ax[1].grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "fig, ax = plot_metrics(\n",
    "    \"Popularity baseline\",\n",
    "    y_pred=val_df[\"global_popularity\"],\n",
    "    y_test=val_df[label_col]\n",
    ")\n",
    "\n",
    "plt.show()  # ✅ Obligatorio en PyCharm"
   ],
   "id": "f472789e0bc0928f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Ahora realizamos un entrenamiento con 2 modelos lineales (L1, L2) y diferentes hiperparámetros.\n",
    "# Preprocesamiento + pipeline + entrenamiento + evaluación."
   ],
   "id": "efdcd90f7568f68c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Preprocesamiento\n",
    "categorical_col = [\"product_type\", \"vendor\"]\n",
    "binary_col = [\"ordered_before\", \"abandoned_before\", \"active_snoozed\", \"set_as_regular\"]\n",
    "numerical_col = [col for col in features_col if col not in categorical_col + binary_col]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numerical_col),  # standardscaler -> media 0 sd 1\n",
    "        (\"cat\", OneHotEncoder(handle_unknown='ignore'), categorical_col)\n",
    "    ],\n",
    "    remainder='passthrough'  # columnas binarias se mantienen tal cual\n",
    ")\n",
    "\n",
    "# Conjuntos\n",
    "X_train = train_df[features_col]\n",
    "y_train = train_df[label_col]\n",
    "X_val = val_df[features_col]\n",
    "y_val = val_df[label_col]"
   ],
   "id": "49200b4e1168e191"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Entrenamiento y papeline\n",
    "predictions = {}\n",
    "estimators = {}\n",
    "scores = {}\n",
    "\n",
    "# Valores de C a explorar\n",
    "C_values = [0.01, 0.1, 1]\n",
    "\n",
    "for penalty in [\"l1\", \"l2\"]:\n",
    "    print(f\"\\n=== Entrenando modelo con penalización {penalty} ===\")\n",
    "\n",
    "    # Definir el modelo base según la penalización\n",
    "    solver = \"liblinear\" if penalty == \"l1\" else \"lbfgs\"\n",
    "    log_reg = LogisticRegression(penalty=penalty, solver=solver, max_iter=1000)\n",
    "\n",
    "    # GridSearchCV para encontrar el mejor C\n",
    "    grid = GridSearchCV(log_reg, param_grid={\"C\": C_values}, scoring=\"average_precision\", cv=5)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    # Mejor modelo y C encontrado\n",
    "    best_C = grid.best_params_[\"C\"]\n",
    "    best_score = grid.best_score_\n",
    "    print(f\"Mejor C para {penalty}: {best_C}, score medio CV={best_score:.4f}\")\n",
    "\n",
    "    # Predicciones sobre el conjunto de validación\n",
    "    y_pred_val = grid.predict_proba(X_val)[:, 1]\n",
    "    ap_val = average_precision_score(y_val, y_pred_val)\n",
    "    print(f\"Average Precision en validación: {ap_val:.4f}\")\n",
    "\n",
    "    # Guardar resultados\n",
    "    predictions[penalty] = y_pred_val\n",
    "    estimators[penalty] = grid.best_estimator_\n",
    "    scores[penalty] = ap_val\n"
   ],
   "id": "a803992e6bb0f397"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Gráficas\n",
    "penalties = list(predictions.keys())\n",
    "\n",
    "# ---------------------\n",
    "# CURVA ROC\n",
    "# ---------------------\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for penalty in penalties:\n",
    "    y_pred = predictions[penalty]\n",
    "    fpr, tpr, _ = roc_curve(y_val, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f\"{penalty.upper()} (AUC = {roc_auc:.3f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "plt.xlabel(\"Tasa de Falsos Positivos (1 - Especificidad)\")\n",
    "plt.ylabel(\"Tasa de Verdaderos Positivos (Sensibilidad)\")\n",
    "plt.title(\"Curvas ROC para diferentes penalizaciones\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---------------------\n",
    "# CURVA PRECISIÓN–RECALL\n",
    "# ---------------------\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for penalty in penalties:\n",
    "    y_pred = predictions[penalty]\n",
    "    precision, recall, _ = precision_recall_curve(y_val, y_pred)\n",
    "    ap = average_precision_score(y_val, y_pred)\n",
    "    plt.plot(recall, precision, lw=2, label=f\"{penalty.upper()} (AP = {ap:.3f})\")\n",
    "\n",
    "plt.xlabel(\"Recall (Sensibilidad)\")\n",
    "plt.ylabel(\"Precisión\")\n",
    "plt.title(\"Curvas Precisión–Recall para diferentes penalizaciones\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "77f8d5096396a07b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# No entiendo por qué no las dibujas. Me falta decir con qué modelo me quedo con cual no y por qué.",
   "id": "43c1e361f0c0c044"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
